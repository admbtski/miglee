# =============================================================================
# OpenTelemetry Collector Configuration - DEVELOPMENT
# =============================================================================
#
# Development configuration with:
#   - 100% sampling (no drops)
#   - Verbose logging
#   - All processors enabled for testing
#   - Debug exporter for troubleshooting
#
# =============================================================================

receivers:
  # OTLP receiver - primary ingestion point for all telemetry
  # Note: 0.0.0.0 binding is intentional for Docker dev environment
  # Allows connections from all containers. Change to 127.0.0.1 in production.
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - 'http://localhost:3000'
            - 'http://localhost:4000'
          allowed_headers:
            - '*'

  # Prometheus receiver - scrape metrics from applications
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 15s
          static_configs:
            - targets: ['localhost:8888']

processors:
  # Memory limiter - prevent OOM
  memory_limiter:
    check_interval: 5s
    limit_mib: 512
    spike_limit_mib: 128

  # Batch processor - efficient export
  batch:
    timeout: 5s
    send_batch_size: 512
    send_batch_max_size: 1024

  # Resource processor - add common attributes
  resource:
    attributes:
      - key: deployment.environment
        value: development
        action: upsert
      - key: telemetry.sdk.name
        value: opentelemetry
        action: upsert

  # Attributes processor - redact sensitive data
  attributes/redact:
    actions:
      # Redact common sensitive fields
      - key: http.request.header.authorization
        action: delete
      - key: http.request.header.cookie
        action: delete
      - key: http.request.header.x-api-key
        action: delete
      # db.statement hash - WARNING: This prevents diagnostics in dev
      # Consider: delete in prod, but allow (or truncate) in dev for debugging
      # Hash kills ability to see actual queries, but delete leaks through other attributes
      - key: db.statement
        action: hash
      # Redact potential PII patterns
      - key: user.email
        action: delete
      - key: user.phone
        action: delete
      - key: enduser.id
        action: hash

  # Transform processor - normalize and enrich
  transform:
    error_mode: ignore
    trace_statements:
      - context: span
        statements:
          # Ensure service.name exists (SAFEGUARD - not primary source)
          # WARNING: If all spans show service.name="unknown", you have instrumentation problems
          # Enforce service.name at application level via OTEL_SERVICE_NAME environment variable
          - set(resource.attributes["service.name"], "unknown") where resource.attributes["service.name"] == nil
          # Normalize HTTP status codes
          - set(attributes["http.status_code_class"], "2xx") where attributes["http.status_code"] >= 200 and attributes["http.status_code"] < 300
          - set(attributes["http.status_code_class"], "4xx") where attributes["http.status_code"] >= 400 and attributes["http.status_code"] < 500
          - set(attributes["http.status_code_class"], "5xx") where attributes["http.status_code"] >= 500
    metric_statements:
      - context: datapoint
        statements:
          - set(resource.attributes["service.name"], "unknown") where resource.attributes["service.name"] == nil
    log_statements:
      - context: log
        statements:
          - set(resource.attributes["service.name"], "unknown") where resource.attributes["service.name"] == nil

exporters:
  # Debug exporter - console output for development
  debug:
    verbosity: basic
    sampling_initial: 5
    sampling_thereafter: 20

  # OTLP exporter to Tempo (traces)
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true

  # Loki exporter (logs)
  loki:
    endpoint: http://loki:3100/loki/api/v1/push
    default_labels_enabled:
      exporter: true
      job: true
      level: true
      service: true

  # Prometheus exporter (metrics)
  prometheus:
    endpoint: 0.0.0.0:8889
    namespace: app
    # Disabled to prevent duplicate label names error
    # resource_to_telemetry_conversion:
    #   enabled: true
    enable_open_metrics: true

# =============================================================================
# Connectors - link pipelines together
# =============================================================================
connectors:
  # Span metrics connector - generate RED metrics from traces
  spanmetrics:
    histogram:
      explicit:
        buckets: [2ms, 5ms, 10ms, 25ms, 50ms, 100ms, 250ms, 500ms, 1s, 2s, 5s]
    dimensions:
      - name: http.method
      - name: http.status_code
      - name: http.route
      # GraphQL-specific dimensions
      # ⚠️ WARNING: graphql.operation.name can cause HIGH CARDINALITY
      # Each unique operation name = new metric series
      # Recommendation: Use persisted queries or enforce stable operationName
      - name: graphql.operation.name
      - name: graphql.operation.type
    dimensions_cache_size: 1000
    aggregation_temporality: AGGREGATION_TEMPORALITY_CUMULATIVE
    metrics_flush_interval: 15s

extensions:
  # Health check endpoint
  health_check:
    endpoint: 0.0.0.0:13133
    path: /health

  # Performance profiling (dev only)
  pprof:
    endpoint: 0.0.0.0:1777

  # zPages for debugging
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]

  telemetry:
    logs:
      level: info
    metrics:
      address: 0.0.0.0:8888

  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp]
      processors:
        - memory_limiter
        - resource
        - attributes/redact
        - transform
        - batch
      exporters: [otlp/tempo, debug, spanmetrics] # Export to Tempo and spanmetrics connector

    # Metrics pipeline (receives from OTLP, Prometheus scraper, and spanmetrics connector)
    metrics:
      receivers: [otlp, prometheus, spanmetrics]
      processors:
        - memory_limiter
        - resource
        - batch
      exporters: [prometheus, debug]

    # Logs pipeline - DISABLED to avoid duplication with Promtail
    # Decision: Use Promtail (stdout→Loki) as primary logs pipeline
    # This prevents duplicate logs and label conflicts
    # logs:
    #   receivers: [otlp]
    #   processors:
    #     - memory_limiter
    #     - resource
    #     - attributes/redact
    #     - transform
    #     - batch
    #   exporters: [debug]  # Only debug, no Loki export
