# Deployment Roadmap: Dev â†’ Stage â†’ Production (AWS + K8s)

> **Cel**: Platform-agnostic konteneryzacja gotowa na Kubernetes, z AWS jako pierwszym targetem.
> **Zasada**: Kod i obrazy sÄ… neutralne, adaptery infrastruktury sÄ… wymienne.

---

## Spis treÅ›ci

1. [Obecny stan](#obecny-stan)
2. [Architektura docelowa](#architektura-docelowa)
3. [Faza 1: Fundamenty](#faza-1-fundamenty)
4. [Faza 2: Kubernetes Manifests](#faza-2-kubernetes-manifests)
5. [Faza 3: CI/CD](#faza-3-cicd)
6. [Faza 4: Observability](#faza-4-observability)
7. [Faza 5: Security Hardening](#faza-5-security-hardening)
8. [Faza 6: Dokumentacja operacyjna](#faza-6-dokumentacja-operacyjna)
9. [Decyzje architektoniczne](#decyzje-architektoniczne)
10. [Checklist przed produkcjÄ…](#checklist-przed-produkcjÄ…)

---

## Obecny stan

> **Ostatnia aktualizacja**: 2024-12-20

| Obszar | Status | Uwagi |
|--------|--------|-------|
| **Dockerfiles** | âœ… Gotowe | Multi-stage, non-root, HEALTHCHECK, production target |
| **Health endpoints** | âœ… Gotowe | `/health/live` (liveness), `/health/ready` (readiness z DB+Redis) |
| **Graceful shutdown** | âœ… Gotowe | SIGTERM/SIGINT, drain connections, close DB/Redis/BullMQ |
| **GraphQL limits** | âœ… Gotowe | depth=7, complexity=1000 (prod) |
| **Next.js standalone** | âœ… Gotowe | `output: 'standalone'` w next.config.ts |
| **Kubernetes manifests** | âŒ Brak | Do stworzenia od zera |
| **CI/CD** | âŒ Brak | GitHub Actions do napisania |
| **OpenTelemetry** | âŒ Brak | Tylko Pino logging |
| **Resolver metrics** | âŒ Brak | Do instrumentacji |
| **WebSocket limits** | âš ï¸ CzÄ™Å›ciowo | Rate limiting jest, brak per-connection limits |
| **Pod security** | âŒ N/A | K8s manifesty nie istniejÄ… |
| **Runbooks** | âŒ Brak | Do napisania |

### Faza 1: Fundamenty - UKOÅƒCZONA âœ…

| Zadanie | Status | Plik |
|---------|--------|------|
| Production Dockerfiles | âœ… | `docker/Dockerfile.api`, `docker/Dockerfile.web` |
| Health /live + /ready | âœ… | `apps/api/src/plugins/health.ts` |
| Graceful shutdown | âœ… | `apps/api/src/plugins/graceful-shutdown.ts` |
| GraphQL depth limit | âœ… | `apps/api/src/plugins/mercurius.ts` (depth=7) |
| GraphQL complexity limit | âœ… | `apps/api/src/plugins/mercurius.ts` (complexity=1000) |
| Next.js standalone output | âœ… | `apps/web/next.config.ts` |
| Docker HEALTHCHECK | âœ… | Dodane do obu Dockerfiles |
| TypeScript build errors | âœ… | Naprawione (unused vars, missing types) |

**Rozmiary obrazÃ³w Docker**:
- `appname-web:production` - **233 MB** (Next.js standalone - zoptymalizowany)
- `appname-api:production` - **1.25 GB** (wymaga optymalizacji - pruning dependencies)

**Build commands**:
```bash
# API
docker build -f docker/Dockerfile.api --target production -t appname-api:$(git rev-parse --short HEAD) .

# Web (wymaga build-args dla public env)
docker build -f docker/Dockerfile.web --target production \
  --build-arg NEXT_PUBLIC_API_URL=https://api.example.com \
  --build-arg NEXT_PUBLIC_WS_URL=wss://api.example.com \
  -t appname-web:$(git rev-parse --short HEAD) .
```

### âš ï¸ Znane problemy do rozwiÄ…zania

| Problem | Priorytet | Akcja |
|---------|-----------|-------|
| Next.js 15.5.4 CVE-2025-66478 | ğŸ”´ Wysoki | ZaktualizowaÄ‡ do najnowszej patched wersji |
| API image 1.25GB | ğŸŸ¡ Åšredni | DodaÄ‡ prune dev dependencies, multi-stage optymalizacja |
| react-qr-reader peer deps | ğŸŸ¢ Niski | ZaktualizowaÄ‡ lub zamieniÄ‡ bibliotekÄ™ |

---

## Architektura docelowa

### Komponenty produkcyjne

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              KUBERNETES CLUSTER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     Web     â”‚    â”‚     API     â”‚    â”‚         Workers             â”‚  â”‚
â”‚  â”‚  Next.js    â”‚â”€â”€â”€â–¶â”‚  Fastify    â”‚â—€â”€â”€â”€â”‚  reminders â”‚ feedback â”‚ auditâ”‚  â”‚
â”‚  â”‚  :3000      â”‚    â”‚  :4000      â”‚    â”‚                             â”‚  â”‚
â”‚  â”‚  2+ repliki â”‚    â”‚  2+ repliki â”‚    â”‚  1 replika kaÅ¼dy            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                         â”‚                   â”‚
â”‚         â–¼                  â–¼                         â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        Managed Services                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚    â”‚
â”‚  â”‚  â”‚   RDS        â”‚   â”‚ ElastiCache  â”‚   â”‚     S3       â”‚         â”‚    â”‚
â”‚  â”‚  â”‚ PostgreSQL   â”‚   â”‚    Redis     â”‚   â”‚   Storage    â”‚         â”‚    â”‚
â”‚  â”‚  â”‚   + PostGIS  â”‚   â”‚              â”‚   â”‚              â”‚         â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS ALB/NLB    â”‚â—€â”€â”€ Internet traffic
â”‚  + WAF (opcja)  â”‚
â”‚  + ACM (TLS)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Åšrodowiska

| Åšrodowisko | Namespace | Cel | Repliki |
|------------|-----------|-----|---------|
| **dev** | `appname-dev` | Lokalne docker-compose | 1 |
| **stage** | `appname-stage` | Test przed prod, mniejsza skala | 1-2 |
| **prod** | `appname-prod` | Produkcja, HA | 2+ |

### Nazewnictwo workloadÃ³w

```
appname-{env}/
â”œâ”€â”€ web                    # Next.js SSR
â”œâ”€â”€ api                    # Fastify GraphQL
â”œâ”€â”€ worker-reminders       # BullMQ worker
â”œâ”€â”€ worker-feedback        # BullMQ worker
â”œâ”€â”€ worker-audit-archive   # BullMQ worker
â”œâ”€â”€ configmap-app          # Konfiguracja jawna
â”œâ”€â”€ secret-app             # Sekrety (z Secrets Manager)
â””â”€â”€ ingress                # Routing + TLS
```

---

## Faza 1: Fundamenty âœ… UKOÅƒCZONA

> **Cel**: Przygotowanie aplikacji do uruchomienia w K8s bez zmian w kodzie.
> **Status**: Wszystkie zadania ukoÅ„czone (2024-12-20)

### 1.1 Production Dockerfiles âœ…

**Status**: âœ… Gotowe  
**Pliki**: `docker/Dockerfile.api`, `docker/Dockerfile.web`

**Zaimplementowane**:
- [x] Multi-stage build (base â†’ deps â†’ builder â†’ production)
- [x] Non-root user (fastify:1001 / nextjs:1001)
- [x] `NODE_ENV=production`
- [x] Tylko produkcyjne dependencies
- [x] Expose port (3000/4000)
- [x] HEALTHCHECK instruction
- [x] Osobne targety: development / production

**Komendy build**:
```bash
# API (production)
docker build -f docker/Dockerfile.api --target production -t appname-api:latest .

# Web (production)
docker build -f docker/Dockerfile.web --target production -t appname-web:latest .
```

### 1.2 Health Endpoints âœ…

**Status**: âœ… Gotowe  
**Plik**: `apps/api/src/plugins/health.ts`

**Zaimplementowane endpointy**:

| Endpoint | Cel | Checks | K8s Probe |
|----------|-----|--------|-----------|
| `GET /health/live` | Liveness | Zawsze 200 | livenessProbe |
| `GET /health/ready` | Readiness | DB + Redis ping | readinessProbe |
| `GET /health` | Legacy | DB + Redis | (backwards compat) |

**Implementacja**:
- DB check: `prisma.$queryRaw\`SELECT 1\``
- Redis check: `redis.ping()`
- Zwraca 503 jeÅ›li ktÃ³rykolwiek fail
- Timeout: 5s (prod) / 10s (dev)

**Web (Next.js)**:
- `/api/health` - endpoint zdrowia (juÅ¼ istnieje)

### 1.3 Graceful Shutdown âœ…

**Status**: âœ… Gotowe  
**Plik**: `apps/api/src/plugins/graceful-shutdown.ts`

**Zaimplementowane**:
- [x] ObsÅ‚uga `SIGTERM`, `SIGINT`, `SIGUSR2`
- [x] Stop accepting new connections
- [x] Drain existing requests (timeout: 30s prod / 10s dev)
- [x] Close DB connections (Prisma)
- [x] Close Redis connections
- [x] Close BullMQ queues
- [x] Force shutdown po 45s (prod) / 15s (dev)
- [x] Returns 503 podczas shutdown

**Sekwencja**:
```
SIGTERM received
    â†“
isShuttingDown = true (returns 503 for new requests)
    â†“
fastify.close() - stop HTTP server
    â†“
wait for in-flight requests (max 30s)
    â†“
prisma.$disconnect()
    â†“
closeAllQueues() (BullMQ)
    â†“
closeAllRedisConnections()  
    â†“
close DB connections
    â†“
process.exit(0)
```

### 1.4 Environment Config Split âœ…

**Status**: âœ… Gotowe  
**Plik**: `apps/api/src/env.ts`

**PodziaÅ‚ ConfigMap vs Secret** (dla K8s):

| ConfigMap (jawne) | Secret (wraÅ¼liwe) |
|-------------------|-------------------|
| `NODE_ENV` | `DATABASE_URL` |
| `PORT` | `REDIS_PASSWORD` |
| `LOG_LEVEL` | `JWT_SECRET` |
| `CORS_ORIGINS` | `STRIPE_SECRET_KEY` |
| `APP_URL` | `STRIPE_WEBHOOK_SECRET` |
| `API_URL` | `RESEND_API_KEY` |
| `ENABLE_BULL_BOARD` | `S3_ACCESS_KEY` |
| `OTEL_*` | `S3_SECRET_KEY` |

**Walidacja**: Zod schema z sensownymi defaults i error messages.

### 1.5 GraphQL Security Limits âœ…

**Status**: âœ… Gotowe  
**Plik**: `apps/api/src/plugins/mercurius.ts`

**Zaimplementowane**:
- [x] Depth limit: `graphql-depth-limit` (prod: 7, dev: 15)
- [x] Complexity limit: custom calculator (prod: 1000, dev: 5000)
- [x] Log when rejected
- [x] Introspection blocked in production

**Konfiguracja**:
```typescript
const MAX_QUERY_DEPTH = config.isProduction ? 7 : 15;
const MAX_QUERY_COMPLEXITY = config.isProduction ? 1000 : 5000;
```

---

## Faza 2: Kubernetes Manifests

> **Cel**: PeÅ‚na definicja K8s resources dla stage/prod.

### 2.1 Struktura katalogÃ³w

**Czas**: 30min

```
infra/
â””â”€â”€ k8s/
    â”œâ”€â”€ base/                    # WspÃ³lne definicje
    â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â”œâ”€â”€ namespace.yaml
    â”‚   â””â”€â”€ labels.yaml
    â”‚
    â”œâ”€â”€ components/              # ReuÅ¼ywalne komponenty
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ deployment.yaml
    â”‚   â”‚   â”œâ”€â”€ service.yaml
    â”‚   â”‚   â””â”€â”€ hpa.yaml
    â”‚   â”œâ”€â”€ web/
    â”‚   â”‚   â”œâ”€â”€ deployment.yaml
    â”‚   â”‚   â”œâ”€â”€ service.yaml
    â”‚   â”‚   â””â”€â”€ hpa.yaml
    â”‚   â””â”€â”€ workers/
    â”‚       â”œâ”€â”€ reminders.yaml
    â”‚       â”œâ”€â”€ feedback.yaml
    â”‚       â””â”€â”€ audit-archive.yaml
    â”‚
    â””â”€â”€ envs/
        â”œâ”€â”€ stage/
        â”‚   â”œâ”€â”€ kustomization.yaml
        â”‚   â”œâ”€â”€ namespace.yaml
        â”‚   â”œâ”€â”€ configmap.yaml
        â”‚   â”œâ”€â”€ ingress.yaml
        â”‚   â””â”€â”€ patches/
        â”‚       â””â”€â”€ replicas.yaml
        â”‚
        â””â”€â”€ prod/
            â”œâ”€â”€ kustomization.yaml
            â”œâ”€â”€ namespace.yaml
            â”œâ”€â”€ configmap.yaml
            â”œâ”€â”€ ingress.yaml
            â”œâ”€â”€ pdb.yaml
            â””â”€â”€ patches/
                â””â”€â”€ replicas.yaml
```

### 2.2 Labels Standard

**Wszystkie workloady muszÄ… mieÄ‡**:
```yaml
metadata:
  labels:
    app.kubernetes.io/name: appname
    app.kubernetes.io/component: api | web | worker-reminders | ...
    app.kubernetes.io/part-of: appname
    app.kubernetes.io/version: <git_sha>
    app.kubernetes.io/managed-by: kustomize
```

### 2.3 API Deployment

**Czas**: 2h  
**Plik**: `infra/k8s/components/api/deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
spec:
  replicas: 2  # Overlay per env
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1
  template:
    spec:
      terminationGracePeriodSeconds: 30
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
      containers:
        - name: api
          image: <ecr>/appname-api:sha-xxx
          ports:
            - containerPort: 4000
          env:
            - name: NODE_ENV
              value: production
          envFrom:
            - configMapRef:
                name: app-config
            - secretRef:
                name: app-secrets
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 500m
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: /healthz
              port: 4000
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /readyz
              port: 4000
            initialDelaySeconds: 5
            periodSeconds: 5
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
```

### 2.4 Web Deployment

**Czas**: 1h  
**Plik**: `infra/k8s/components/web/deployment.yaml`

Analogicznie do API, ale:
- Port: 3000
- Image: `appname-web:sha-xxx`
- Health: `/api/health`

### 2.5 Workers Deployments

**Czas**: 1h  
**Pliki**: `infra/k8s/components/workers/*.yaml`

```yaml
# worker-reminders.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: worker-reminders
spec:
  replicas: 1
  template:
    spec:
      containers:
        - name: worker
          image: <ecr>/appname-api:sha-xxx  # Ten sam obraz co API
          command: ["pnpm", "worker:reminders"]
          # Brak portÃ³w
          # Brak probes HTTP (opcjonalnie exec probe)
```

### 2.6 Ingress

**Czas**: 1h  
**Plik**: `infra/k8s/envs/{stage,prod}/ingress.yaml`

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: appname-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/certificate-arn: <acm-cert-arn>
spec:
  rules:
    - host: app.domain.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: web
                port:
                  number: 3000
    - host: api.domain.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: api
                port:
                  number: 4000
```

### 2.7 HPA + PDB

**Czas**: 1h

**HorizontalPodAutoscaler**:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

**PodDisruptionBudget**:
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-pdb
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: api
```

### 2.8 Migration Job

**Czas**: 1h  
**Plik**: `infra/k8s/components/jobs/migrate.yaml`

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: migrate-{{ .Values.sha }}
spec:
  backoffLimit: 3
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: migrate
          image: <ecr>/appname-api:sha-xxx
          command: ["pnpm", "-C", "apps/api", "prisma:migrate", "deploy"]
          envFrom:
            - secretRef:
                name: app-secrets
```

---

## Faza 3: CI/CD

> **Cel**: Automatyczny pipeline build â†’ test â†’ deploy.

### 3.1 Workflow: PR Validation (`ci.yml`)

**Czas**: 1h  
**Trigger**: Pull Request

```yaml
name: CI
on:
  pull_request:
    branches: [main]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
      - uses: actions/setup-node@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm lint
      - run: pnpm typecheck
      - run: pnpm test  # gdy bÄ™dÄ… testy
```

### 3.2 Workflow: Build & Push (`build.yml`)

**Czas**: 2h  
**Trigger**: Push to main / Tag

```yaml
name: Build
on:
  push:
    branches: [main]
    tags: ['v*']

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        
      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v2
        
      - name: Build API image
        run: |
          docker build -f docker/Dockerfile.api.prod \
            -t $ECR_REGISTRY/appname-api:sha-${{ github.sha }} .
          docker push $ECR_REGISTRY/appname-api:sha-${{ github.sha }}
          
      - name: Build Web image
        run: |
          docker build -f docker/Dockerfile.web.prod \
            -t $ECR_REGISTRY/appname-web:sha-${{ github.sha }} .
          docker push $ECR_REGISTRY/appname-web:sha-${{ github.sha }}
```

### 3.3 Workflow: Deploy Stage (`deploy-stage.yml`)

**Czas**: 2h  
**Trigger**: Push to main (after build)

```yaml
name: Deploy Stage
on:
  workflow_run:
    workflows: [Build]
    types: [completed]
    branches: [main]

jobs:
  deploy:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    environment: stage
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure kubectl
        uses: aws-actions/amazon-eks-update-kubeconfig@v2
        
      - name: Run migrations
        run: |
          kubectl apply -f infra/k8s/jobs/migrate.yaml
          kubectl wait --for=condition=complete job/migrate-$SHA
          
      - name: Deploy
        run: |
          cd infra/k8s/envs/stage
          kustomize edit set image appname-api=$ECR/appname-api:sha-$SHA
          kustomize edit set image appname-web=$ECR/appname-web:sha-$SHA
          kustomize build . | kubectl apply -f -
          
      - name: Wait for rollout
        run: |
          kubectl rollout status deployment/api -n appname-stage
          kubectl rollout status deployment/web -n appname-stage
          
      - name: Smoke test
        run: |
          curl -f https://api.stage.domain.com/healthz
          curl -f https://app.stage.domain.com/api/health
```

### 3.4 Workflow: Deploy Prod (`deploy-prod.yml`)

**Czas**: 2h  
**Trigger**: Tag + Manual approval

```yaml
name: Deploy Prod
on:
  push:
    tags: ['v*']

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: prod  # Wymaga approval w GitHub
    steps:
      # ... analogicznie do stage
      # + snapshot DB przed migracjÄ…
```

---

## Faza 4: Observability

> **Cel**: WidzieÄ‡ co siÄ™ dzieje w systemie.

### 4.1 OpenTelemetry SDK

**Czas**: 2h  
**Plik**: `apps/api/src/lib/otel.ts`

**Wymagania**:
- [ ] ZainstalowaÄ‡: `@opentelemetry/sdk-node`, `@opentelemetry/auto-instrumentations-node`
- [ ] Konfiguracja exportera OTLP
- [ ] Propagacja kontekstu (trace_id)
- [ ] Instrumentacja HTTP/Fastify

### 4.2 Resolver Metrics

**Czas**: 2h  
**Plik**: `apps/api/src/graphql/utils/resolver-metrics.ts`

```typescript
// Wrapper dla resolverÃ³w
// Mierzy: histogram czasu, counter bÅ‚Ä™dÃ³w
// Labels: gql_type, field, success

const resolverDuration = new Histogram({
  name: 'graphql_resolver_duration_seconds',
  help: 'GraphQL resolver duration',
  labelNames: ['type', 'field', 'success'],
  buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
});
```

### 4.3 Trace ID in Logs

**Czas**: 1h  
**Plik**: `apps/api/src/lib/pino.ts`

```typescript
// DodaÄ‡ do kaÅ¼dego loga:
// trace_id, span_id z OTel context
```

### 4.4 Metryki minimum

| Metryka | Typ | Labels |
|---------|-----|--------|
| `http_request_duration_seconds` | Histogram | method, path, status |
| `graphql_resolver_duration_seconds` | Histogram | type, field, success |
| `graphql_errors_total` | Counter | type, code |
| `db_query_duration_seconds` | Histogram | operation |
| `redis_operation_duration_seconds` | Histogram | command |
| `ws_connections_active` | Gauge | - |
| `bullmq_jobs_total` | Counter | queue, status |
| `bullmq_job_duration_seconds` | Histogram | queue |

### 4.5 Alerty minimum (prod)

| Alert | Warunek | Severity |
|-------|---------|----------|
| API high latency | p95 > 2s przez 5min | warning |
| API error rate | 5xx > 5% przez 5min | critical |
| API down | 0 healthy pods | critical |
| DB connection errors | > 10/min | critical |
| Redis errors | > 10/min | warning |
| Worker backlog | oldest job > 30min | warning |
| Pod restarts | > 3 w 10min | warning |
| HPA maxed out | replicas = max przez 10min | warning |

---

## Faza 5: Security Hardening

> **Cel**: Minimalizacja powierzchni ataku.

### 5.1 Pod Security

**Wszystkie pody muszÄ… mieÄ‡**:
```yaml
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop: ["ALL"]
```

### 5.2 RBAC

- [ ] Osobny ServiceAccount per workload
- [ ] Brak cluster-admin w podach
- [ ] Namespace-scoped roles

### 5.3 Network Policies (docelowo)

```yaml
# Tylko API moÅ¼e gadaÄ‡ z DB
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: db-access
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: api
  policyTypes:
    - Egress
  egress:
    - to:
        - ipBlock:
            cidr: <rds-subnet>/24
      ports:
        - port: 5432
```

### 5.4 Secrets Management

**Docelowo**: AWS Secrets Manager + External Secrets Operator

```yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: app-secrets
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: aws-secrets-manager
    kind: ClusterSecretStore
  target:
    name: app-secrets
  data:
    - secretKey: DATABASE_URL
      remoteRef:
        key: appname/prod/database
        property: url
```

### 5.5 API Security Checklist

- [ ] Rate limiting na wszystkich endpointach
- [ ] CORS poprawnie skonfigurowany
- [ ] Secure cookies (HttpOnly, Secure, SameSite)
- [ ] GraphQL depth limit
- [ ] GraphQL complexity limit
- [ ] WebSocket connection limits
- [ ] Input validation (Zod)
- [ ] SQL injection protection (Prisma)
- [ ] XSS protection (helmet)

---

## Faza 6: Dokumentacja operacyjna

### 6.1 Runbook: API Down

```markdown
## Symptomy
- /healthz zwraca 5xx lub timeout
- Alerty o braku healthy pods

## Diagnostyka
1. kubectl get pods -n appname-prod -l component=api
2. kubectl logs -n appname-prod deployment/api --tail=100
3. kubectl describe pod <pod-name>

## Recovery
1. JeÅ›li CrashLoopBackOff â†’ sprawdÅº logi, rollback jeÅ›li nowy deploy
2. JeÅ›li OOMKilled â†’ zwiÄ™ksz memory limits
3. JeÅ›li DB/Redis unreachable â†’ sprawdÅº managed services
```

### 6.2 Runbook: DB Issues

```markdown
## Connection refused
1. SprawdÅº RDS status w AWS Console
2. SprawdÅº Security Groups
3. SprawdÅº DATABASE_URL w secrets

## Slow queries
1. SprawdÅº RDS Performance Insights
2. SprawdÅº connection pool exhaustion
3. EXPLAIN problematic queries
```

### 6.3 Runbook: Rollback

```markdown
## Rollback kodu
1. ZnajdÅº poprzedni SHA: git log --oneline -10
2. kubectl set image deployment/api api=ecr/appname-api:sha-<PREV>
3. kubectl set image deployment/web web=ecr/appname-web:sha-<PREV>
4. kubectl rollout status deployment/api deployment/web

## Rollback DB (destrukcyjna migracja)
1. Upewnij siÄ™ Å¼e masz snapshot sprzed migracji
2. Restore snapshot do nowej instancji RDS
3. Update DATABASE_URL w secrets
4. Restart deployments
```

### 6.4 Runbook: Secret Rotation

```markdown
## JWT_SECRET
1. Wygeneruj nowy secret
2. Update w Secrets Manager
3. Restart api deployment (graceful)
4. UÅ¼ytkownicy muszÄ… siÄ™ przelogowaÄ‡

## STRIPE_WEBHOOK_SECRET
1. Wygeneruj nowy endpoint w Stripe Dashboard
2. Update secret
3. Restart api

## DATABASE_URL (password change)
1. Change password w RDS
2. Update secret
3. Restart wszystkich workloadÃ³w
```

---

## Decyzje architektoniczne

### ADR-001: Managed Services

**Decyzja**: UÅ¼ywamy managed services (RDS, ElastiCache) zamiast self-hosted w K8s.

**Uzasadnienie**:
- Mniejszy overhead operacyjny
- Automatyczne backupy
- HA out-of-the-box
- Lock-in tylko na poziomie infra, nie kodu

### ADR-002: Jeden obraz API dla workerÃ³w

**Decyzja**: Workers uÅ¼ywajÄ… tego samego obrazu co API, rÃ³Å¼ne `command`.

**Uzasadnienie**:
- Mniej buildÃ³w
- Brak dryfu wersji
- Åatwiejszy debug

### ADR-003: Migracje jako K8s Job

**Decyzja**: Prisma migrate deploy jako Job przed rollout, nie w API start.

**Uzasadnienie**:
- Brak race conditions przy wielu replikach
- Jasny punkt failure w pipeline
- MoÅ¼liwoÅ›Ä‡ retry/rollback

### ADR-004: Redis Pub/Sub dla realtime

**Decyzja**: UÅ¼ywamy Redis Pub/Sub jako backplane dla WebSocket/subscriptions.

**Uzasadnienie**:
- Prosty setup
- WystarczajÄ…cy dla "best-effort" realtime
- JuÅ¼ zaimplementowane (mqemitter-redis)

**Ograniczenia**:
- Brak gwarancji dostarczenia (OK dla UI updates)
- Krytyczne eventy muszÄ… iÅ›Ä‡ przez DB

---

## Checklist przed produkcjÄ…

### Infrastruktura

- [ ] EKS cluster utworzony
- [ ] RDS PostgreSQL + PostGIS skonfigurowany
- [ ] ElastiCache Redis skonfigurowany
- [ ] S3 bucket utworzony
- [ ] ECR repositories utworzone
- [ ] ACM certificate dla domen
- [ ] ALB Ingress Controller zainstalowany
- [ ] External Secrets Operator zainstalowany
- [ ] Metrics Server zainstalowany

### Aplikacja

- [ ] Production Dockerfiles dziaÅ‚ajÄ…
- [ ] /healthz i /readyz dziaÅ‚ajÄ…
- [ ] Graceful shutdown dziaÅ‚a
- [ ] GraphQL limits skonfigurowane
- [ ] Rate limiting dziaÅ‚a
- [ ] CORS poprawny

### CI/CD

- [ ] Build pipeline dziaÅ‚a
- [ ] Deploy stage dziaÅ‚a
- [ ] Deploy prod z approval dziaÅ‚a
- [ ] Rollback przetestowany

### Observability

- [ ] Logi trafiajÄ… do systemu
- [ ] Metryki zbierane
- [ ] Dashboardy skonfigurowane
- [ ] Alerty skonfigurowane
- [ ] On-call rotation ustalona

### Security

- [ ] Sekrety w Secrets Manager
- [ ] Pod security contexts
- [ ] RBAC skonfigurowany
- [ ] Backup RDS dziaÅ‚a
- [ ] Test restore wykonany

### Dokumentacja

- [ ] Runbooki napisane
- [ ] Architektura udokumentowana
- [ ] Onboarding guide dla devÃ³w

---

## Timeline (orientacyjny)

| Faza | Czas | ZaleÅ¼noÅ›ci |
|------|------|------------|
| Faza 1: Fundamenty | 1 tydzieÅ„ | - |
| Faza 2: K8s Manifests | 1-2 tygodnie | Faza 1 |
| Faza 3: CI/CD | 1 tydzieÅ„ | Faza 2 |
| Faza 4: Observability | 1 tydzieÅ„ | Faza 2 |
| Faza 5: Security | 1 tydzieÅ„ | Faza 2, 3 |
| Faza 6: Runbooks | 2-3 dni | Faza 1-5 |
| **TOTAL** | **5-7 tygodni** | |

---

*Dokument utworzony: 2024-12-20*  
*Ostatnia aktualizacja: 2024-12-20*

