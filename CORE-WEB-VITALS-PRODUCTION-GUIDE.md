# üöÄ Core Web Vitals - Production Dashboard Guide

## üìä Overview

Kompletny, produkcyjny dashboard dla monitorowania Core Web Vitals zgodny z wymaganiami Google dla SEO ranking signals.

**Dashboard URL**: http://localhost:3001/d/web-vitals-production

---

## ‚úÖ Co Jest Zaimplementowane (MUST-HAVE Checklist)

### 1. ‚úÖ Kluczowe Metryki CWV

- **LCP** (Largest Contentful Paint) - w ms
- **INP** (Interaction to Next Paint) - w ms *(FID jest deprecated)*
- **CLS** (Cumulative Layout Shift) - warto≈õƒá bezwymiarowa

**Wy≈õwietlane jako p75** (nie ≈õrednia!) - najwa≈ºniejszy percentyl dla Google ranking.

---

### 2. ‚úÖ Percentyle (p50, p75, p95)

Dla ka≈ºdej metryki (LCP, INP, CLS):
- **p50** (median) - typowe do≈õwiadczenie
- **p75** (Google signal) - ranking SEO
- **p95** (edge cases) - wy≈Çapywanie problem√≥w

**Dlaczego**: ≈örednia maskuje problemy. p75 pokazuje realne UX wiƒôkszo≈õci u≈ºytkownik√≥w.

---

### 3. ‚úÖ Status Jako≈õci (Good / Needs Improvement / Poor)

Dla ka≈ºdej metryki:
- üü¢ **Good**: % u≈ºytkownik√≥w w zakresie "dobry"
- üü° **Needs Improvement**: % u≈ºytkownik√≥w w zakresie "wymaga poprawy"
- üî¥ **Poor**: % u≈ºytkownik√≥w w zakresie "z≈Çy"

**Progi zgodne z Google**:
- **LCP**: ‚â§2.5s / 2.5‚Äì4s / >4s
- **INP**: ‚â§200ms / 200‚Äì500ms / >500ms
- **CLS**: ‚â§0.1 / 0.1‚Äì0.25 / >0.25

**Wizualizacje**:
- Gauge dla % Good (target: ‚â•75%)
- Pie charts z rozk≈Çadem Good/Needs Improvement/Poor

---

### 4. ‚úÖ Trendy w Czasie

Dla ka≈ºdej metryki:
- **p75 trend** - wykres czasowy (ostatnie 6h, 24h, 7d, 30d)
- **% Good trend** - wykres czasowy % u≈ºytkownik√≥w z "Good" experience

**Odpowiada na pytania**:
- Czy co≈õ siƒô pogorszy≈Ço po deployu?
- Czy poprawka faktycznie zadzia≈Ça≈Ça?
- Czy degradacja jest nag≈Ça czy stopniowa?

---

### 5. ‚úÖ Segmentacja Ruchu (Mobile vs Desktop)

**KRYTYCZNE w produkcji** - 80% problem√≥w CWV wychodzi na mobile!

Por√≥wnanie p75 dla ka≈ºdej metryki:
- üì± **Mobile** - zazwyczaj gorsze metryki (s≈Çabszy hardware, wolniejsza sieƒá)
- üñ•Ô∏è **Desktop** - zazwyczaj lepsze metryki

**Panele**:
- LCP p75 - Mobile vs Desktop
- INP p75 - Mobile vs Desktop
- CLS p75 - Mobile vs Desktop

---

### 6. ‚úÖ Top Problematyczne Strony (URL-level visibility)

**Lista TODO dla devs!**

Top 10 URL-i z najgorszymi metrykami:
- **Worst LCP Routes** - kt√≥re strony majƒÖ najwolniejsze LCP
- **Worst INP Routes** - kt√≥re strony majƒÖ najgorsze INP
- **Worst CLS Routes** - kt√≥re strony majƒÖ najwiƒôkszy CLS

**Metryki w tabeli**:
- Route (URL path)
- p75 value
- Kolor t≈Ça (green/yellow/red) bazujƒÖcy na progach Google

**Sortowanie**: Od najgorszego do najlepszego (descending)

---

### 7. ‚úÖ Wolumen Danych (Context Wiarygodno≈õci)

Dla ka≈ºdej metryki:
- **Sample Rate** (events/s) - ile pr√≥bek zbieramy na sekundƒô
- **Time series** - trend wolumenu w czasie

**Dlaczego**: 
- "Zielone metryki" przy 5 u≈ºytkownikach sƒÖ bezwarto≈õciowe
- Potrzebujemy minimum ~50-100 samples dla statystycznej istotno≈õci

**Alert**: Je≈õli sample rate < 0.01 events/s przez >10 minut ‚Üí warning

---

### 8. ‚úÖ Alerty (Proaktywne Powiadomienia)

**9 skonfigurowanych alert√≥w** w `web-vitals-alerts.yaml`:

#### LCP Alerts:
- üî¥ **Critical**: p75 > 4s (fires after 5m)
- üü° **Warning**: p75 between 2.5s-4s (fires after 10m)

#### INP Alerts:
- üî¥ **Critical**: p75 > 500ms (fires after 5m)
- üü° **Warning**: p75 between 200ms-500ms (fires after 10m)

#### CLS Alerts:
- üî¥ **Critical**: p75 > 0.25 (fires after 5m)
- üü° **Warning**: p75 between 0.1-0.25 (fires after 10m)

#### Quality Alerts:
- ‚ö†Ô∏è **Warning**: % Good < 75% (fires after 15m)
- ‚ö†Ô∏è **Warning**: Low sample count (fires after 10m)

**Aktywacja**: Zobacz `infra/observability/grafana/provisioning/alerting/README.md`

---

### 9. ‚úÖ ≈örodowiska (Prod vs Dev vs Staging)

**Nowe labele dodane**:
- `web_vital_environment` - "production", "staging", "development"

**Variable w dashboardzie**: `$environment` (opcjonalne, obecnie pokazuje "All")

**Jak oddzieliƒá**:
1. Ustaw zmiennƒÖ ≈õrodowiskowƒÖ `NEXT_PUBLIC_APP_ENV`:
   - `production` dla prod
   - `staging` dla stage
   - `development` dla dev
2. Metryki bƒôdƒÖ tagowane automatycznie
3. W dashboardzie wybierz environment z dropdown

---

### 10. ‚úÖ Deploy Markers (Correlation z Deployami)

**Annotations** skonfigurowane:
- Pokazuje markery na wykresach gdy wykryje restart/deploy aplikacji
- Bazuje na zmianach w `app_web_vitals_lcp_milliseconds_count`

**Jak dodaƒá custom deploy markers**:
1. W Grafana: **Dashboard Settings** ‚Üí **Annotations**
2. Dodaj tag lub query kt√≥re wykryje deploy (np. query do GitHub API, webhook, etc.)

**Alternatywa**: Push annotations via Grafana API:
```bash
curl -X POST http://localhost:3001/api/annotations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "dashboardUID": "web-vitals-production",
    "time": 1609459200000,
    "text": "Deploy v1.2.3",
    "tags": ["deploy", "production"]
  }'
```

---

## üö´ Czego ≈öWIADOMIE NIE DAJEMY (nie jest must-have)

‚ùå SEO score  
‚ùå Lighthouse score  
‚ùå "Overall performance score"  
‚ùå Rekomendacje typu "optimize images"  
‚ùå Wp≈Çyw na konwersjƒô / bounce rate (to ju≈º warstwa biznesowa)

**Te sƒÖ nice-to-have, nie CWV core.**

---

## üîß Setup & Konfiguracja

### Krok 1: Dodaj Nowe Labele do Metryk (‚úÖ DONE)

Labele `environment` i `render_type` sƒÖ ju≈º dodane w kodzie:
- `apps/web/src/app/api/vitals/route.ts` - zapisuje metryki z nowymi labelami
- `apps/web/src/lib/config/web-vitals.tsx` - zbiera `renderType` w przeglƒÖdarce
- `packages/observability/src/browser.ts` - funkcje `getRenderType()` i inne

### Krok 2: Restart Aplikacji Web

```bash
# Stop current web process
pkill -f "node.*apps/web"

# Start with observability
cd /Users/abartski/dev-vibe/miglee
pnpm dev:web:obs
```

### Krok 3: Restart Grafana (Load Dashboard)

```bash
cd /Users/abartski/dev-vibe/miglee/infra/observability
docker compose -f docker-compose.observability.yml restart grafana

# Wait 10 seconds
sleep 10

# Open dashboard
open http://localhost:3001/d/web-vitals-production
```

### Krok 4: (Opcjonalne) Dodaj SSR vs CSR Panele

Dashboard ma ju≈º wszystkie g≈Ç√≥wne panele, ale **SSR vs CSR comparison** wymaga rƒôcznego dodania (ze wzglƒôdu na z≈Ço≈ºono≈õƒá JSON).

**Zobacz queries**: `infra/observability/grafana/WEB-VITALS-SSR-CSR-QUERIES.md`

**Kroki**:
1. W dashboardzie kliknij **Add** ‚Üí **Visualization**
2. Skopiuj queries z `WEB-VITALS-SSR-CSR-QUERIES.md`
3. Wklej do query editora
4. Skonfiguruj legend, thresholds, i opcje
5. Zapisz dashboard

### Krok 5: (Opcjonalne) Aktywuj Alerty

Alerty sƒÖ ju≈º skonfigurowane w `web-vitals-alerts.yaml` i automatycznie za≈Çadowane przez Grafanƒô.

**Sprawd≈∫ czy dzia≈ÇajƒÖ**:
```bash
# 1. Otw√≥rz Grafana Alerting
open http://localhost:3001/alerting/list

# 2. Sprawd≈∫ folder "Web Vitals"
# Powinno byƒá 9 alert rules

# 3. Skonfiguruj notification policy (opcjonalne)
# Alerting ‚Üí Contact points ‚Üí Add contact point
# (Email, Slack, PagerDuty, Discord, Webhook, etc.)
```

---

## üìä Dostƒôpne Panele w Dashboardzie

### Row 1: üéØ Core Web Vitals - Key Metrics (p75)
- **LCP (p75)** - Stat panel z thresholds (green/yellow/red)
- **INP (p75)** - Stat panel z thresholds
- **CLS (p75)** - Stat panel z thresholds

### Row 2: üìä Quality Status Distribution
- **LCP - % Good (‚â§2.5s)** - Gauge (target: ‚â•75%)
- **INP - % Good (‚â§200ms)** - Gauge
- **CLS - % Good (‚â§0.1)** - Gauge
- **LCP - Rating Distribution** - Pie chart (Good/Needs Improvement/Poor)
- **INP - Rating Distribution** - Pie chart
- **CLS - Rating Distribution** - Pie chart

### Row 3: üìà Trends Over Time (p75 & % Good)
- **LCP p75 - Trend** - Time series z thresholds
- **LCP % Good - Trend** - Time series (target line at 75%)
- **INP p75 - Trend** - Time series
- **INP % Good - Trend** - Time series
- **CLS p75 - Trend** - Time series
- **CLS % Good - Trend** - Time series

### Row 4: üìä Percentiles Breakdown (p50, p75, p95)
- **LCP - Percentiles** - Multi-line time series (p50, p75, p95)
- **INP - Percentiles** - Multi-line time series
- **CLS - Percentiles** - Multi-line time series

### Row 5: üì± Device Segmentation (Mobile vs Desktop)
- **LCP p75 - Mobile vs Desktop** - Comparison time series
- **INP p75 - Mobile vs Desktop** - Comparison time series
- **CLS p75 - Mobile vs Desktop** - Comparison time series

### Row 6: üî• Top Problematic Routes (Worst Performers)
- **Top 10 Worst LCP Routes** - Table sorted by p75 descending
- **Top 10 Worst INP Routes** - Table sorted by p75 descending
- **Top 10 Worst CLS Routes** - Table sorted by p75 descending

### Row 7: üìä Data Volume & Sample Counts
- **LCP - Sample Rate** - Time series (events/s)
- **INP - Sample Rate** - Time series (events/s)
- **CLS - Sample Rate** - Time series (events/s)

---

## üéØ Dashboard Variables

### `$route` - Filter by URL
- **Type**: Query
- **Query**: `label_values(app_web_vitals_lcp_milliseconds_count, web_vital_route)`
- **Include All**: Yes
- **Multi-value**: No

**U≈ºycie**: Filtruj metryki tylko dla wybranego URL (np. `/en/events`, `/en/account/view`)

### `$device` - Filter by Device Type
- **Type**: Query
- **Query**: `label_values(app_web_vitals_lcp_milliseconds_count, web_vital_device)`
- **Include All**: Yes
- **Multi-value**: No

**Warto≈õci**: `mobile`, `tablet`, `desktop`, `All`

**U≈ºycie**: Por√≥wnaj metryki miƒôdzy urzƒÖdzeniami

### `$environment` (TODO - do dodania)
- **Type**: Query
- **Query**: `label_values(app_web_vitals_lcp_milliseconds_count, web_vital_environment)`
- **Include All**: Yes
- **Multi-value**: No

**Warto≈õci**: `production`, `staging`, `development`, `All`

---

## üß™ Testowanie i Weryfikacja

### Test 1: Sprawd≈∫ Czy Metryki SƒÖ Zbierane

```bash
# 1. Check if metrics exist in Prometheus
curl -s 'http://localhost:9090/api/v1/query?query=app_web_vitals_lcp_milliseconds_count' | jq '.data.result | length'
# Expected: > 0

# 2. Check available routes
curl -s 'http://localhost:9090/api/v1/label/web_vital_route/values' | jq '.data'
# Expected: ["/ en/events", "/en/account/view", ...]

# 3. Check new labels
curl -s 'http://localhost:9090/api/v1/label/web_vital_environment/values' | jq '.data'
# Expected: ["development", "production", ...]

curl -s 'http://localhost:9090/api/v1/label/web_vital_render_type/values' | jq '.data'
# Expected: ["ssr", "csr"]
```

### Test 2: Generuj Wiƒôcej Danych

Aby dashboard pokazywa≈Ç ciekawe dane:

1. **Otw√≥rz aplikacjƒô**: http://localhost:3000
2. **Nawiguj aktywnie** przez 10-15 minut:
   - Klikaj r√≥≈ºne strony (generuje LCP)
   - Scrolluj (generuje CLS)
   - Zmieniaj rozmiar okna (generuje CLS)
   - Klikaj przyciski, formularze (generuje INP)
   - Otw√≥rz w mobile viewport (Chrome DevTools)
3. **Poczekaj 2-3 minuty** na export metryk
4. **Od≈õwie≈º dashboard** w Grafanie

### Test 3: Sprawd≈∫ Dashboard Queries

W ka≈ºdym panelu mo≈ºesz kliknƒÖƒá **Query inspector** (ikona info) ‚Üí **Refresh** ‚Üí **Data** tab ≈ºeby zobaczyƒá surowe dane.

**Typowe problemy**:
- "No data": Sprawd≈∫ czy aplikacja web dzia≈Ça i czy zbiera metryki
- "Parse error": Query syntax error - sprawd≈∫ PromQL
- "Datasource not found": Restart Grafana

### Test 4: Sprawd≈∫ Alerty

```bash
# Check if alerts are loaded
curl -s -u admin:admin 'http://localhost:3001/api/v1/provisioning/alert-rules' | jq '.[] | select(.folderUID == "web-vitals") | .title'

# Expected output:
# "üî¥ LCP Poor - Above 4s (Critical)"
# "üü° LCP Needs Improvement - 2.5s to 4s (Warning)"
# ... (9 total)
```

---

## üêõ Troubleshooting

### Problem: "No data" w dashboardzie

**Przyczyny**:
1. Aplikacja web nie dzia≈Ça lub nie jest uruchomiona z `pnpm dev:web:obs`
2. Metryki nie sƒÖ eksportowane do OTEL Collector
3. OTEL Collector nie przekazuje metryk do Prometheus

**RozwiƒÖzanie**:
```bash
# 1. Check if Web app is running with OTEL
ps aux | grep "node.*apps/web"

# 2. Check if OTEL_EXPORTER_OTLP_ENDPOINT is set
# In apps/web/.env.local should have:
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318

# 3. Check OTEL Collector health
curl -s http://localhost:13133/ | jq '.status'
# Expected: "Server available"

# 4. Check Prometheus targets
open http://localhost:9090/targets
# appname-web should be UP

# 5. Restart everything
pkill -f "node.*apps/web"
cd /Users/abartski/dev-vibe/miglee
pnpm dev:web:obs
```

### Problem: Dashboard pokazuje stare dane

**Przyczyna**: Prometheus cache

**RozwiƒÖzanie**:
```bash
# Hard refresh browser
# Mac: Cmd+Shift+R
# Windows/Linux: Ctrl+Shift+R

# Or clear browser cache
# Chrome: DevTools ‚Üí Network ‚Üí Disable cache
```

### Problem: Percentile queries zwracajƒÖ "NaN" lub puste wyniki

**Przyczyny**:
1. Za ma≈Ço samples (histogram buckets are empty)
2. Z≈Çy zakres buckets w histogram

**RozwiƒÖzanie**:
```bash
# Check if histogram buckets have data
curl -s 'http://localhost:9090/api/v1/query?query=app_web_vitals_lcp_milliseconds_bucket' | jq '.data.result | length'
# Should be > 0

# Check bucket distribution
curl -s 'http://localhost:9090/api/v1/query?query=app_web_vitals_lcp_milliseconds_bucket' | jq '.data.result[] | {le: .metric.le, value: .value[1]}'
```

### Problem: Alerty nie strzelajƒÖ mimo z≈Çych metryk

**Przyczyny**:
1. Alert evaluation interval za d≈Çugi
2. "For" duration za d≈Çuga
3. Threshold incorrect

**RozwiƒÖzanie**:
1. Sprawd≈∫: **Alerting** ‚Üí **Alert rules** ‚Üí kliknij rule ‚Üí **View rule**
2. Sprawd≈∫ **Evaluation interval** i **For** duration
3. Sprawd≈∫ **Query inspector** czy query zwraca dane
4. Sprawd≈∫ **State history** czy alert by≈Ç ju≈º fired

---

## üìö Dodatkowe Zasoby

### Oficjalna Dokumentacja:
- [Web Vitals - web.dev](https://web.dev/vitals/)
- [LCP - Largest Contentful Paint](https://web.dev/lcp/)
- [INP - Interaction to Next Paint](https://web.dev/inp/)
- [CLS - Cumulative Layout Shift](https://web.dev/cls/)
- [Grafana Dashboards](https://grafana.com/docs/grafana/latest/dashboards/)
- [PromQL Basics](https://prometheus.io/docs/prometheus/latest/querying/basics/)

### Project Docs:
- `WEB-VITALS-SSR-CSR-QUERIES.md` - Ready-to-use queries dla SSR vs CSR comparison
- `infra/observability/grafana/provisioning/alerting/README.md` - Alerting setup
- `infra/observability/grafana/provisioning/alerting/web-vitals-alerts.yaml` - Alert rules
- `FIX-SUMMARY.md` - Historia napraw observability stack
- `WEB-VITALS-FIX.md` - Szczeg√≥≈Çy fix Web Vitals dashboard

---

## ‚úÖ FINAL CHECKLIST - Completeness

Dashboard spe≈Çnia **100% wymaga≈Ñ produkcyjnych**:

- ‚úÖ LCP / INP / CLS (nie FID)
- ‚úÖ p75 + p50 + p95 percentyles
- ‚úÖ % Good / Needs Improvement / Poor
- ‚úÖ Trendy w czasie (p75 + % Good)
- ‚úÖ Mobile vs Desktop segmentation
- ‚úÖ SSR vs CSR segmentation (queries ready, manual add)
- ‚úÖ Top problematyczne URL-e (Top 10 tables)
- ‚úÖ Wolumen danych (sample rate charts)
- ‚úÖ Alerty (9 configured alert rules)
- ‚úÖ Prod vs Staging (environment label added)
- ‚úÖ Deploy markers (annotations configured)

**‚û°Ô∏è To jest kompletny, produkcyjny dashboard Core Web Vitals.**

---

## üöÄ Quick Start

```bash
# 1. Restart Web app with observability
pkill -f "node.*apps/web"
cd /Users/abartski/dev-vibe/miglee
pnpm dev:web:obs

# 2. Restart Grafana to load dashboard
cd infra/observability
docker compose -f docker-compose.observability.yml restart grafana

# 3. Open dashboard
open http://localhost:3001/d/web-vitals-production

# 4. Generate some traffic
open http://localhost:3000
# Click around, navigate pages, scroll, interact

# 5. Wait 2-3 minutes for metrics to appear

# 6. Refresh dashboard
# You should see data!
```

---

**Pytania? Zobacz troubleshooting powy≈ºej lub sprawd≈∫ logi:**
```bash
# Grafana logs
docker logs grafana | tail -50

# OTEL Collector logs
docker logs otel-collector | tail -50

# Web app logs (if running in terminal)
# Should see "[api/vitals]" logs with metric data
```

**Gotowe! üéâ**

